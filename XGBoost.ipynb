{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from time import time\n",
    "import csv\n",
    "import pickle\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pandas import HDFStore,DataFrame\n",
    "from pandas import read_hdf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Libraries to perform hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance  ## to plot feature importance\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix\n",
    "\n",
    "# To save the final model on disk\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train = read_hdf('storage_sample_stage3-V3.h5', 'train_df',mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_test = read_hdf('storage_sample_stage3-V3.h5', 'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source', 'sink', 'edge_indecator', 'jaccard_followers',\n",
       "       'jaccard_for_followees', 'cosine_followers', 'cosine_followees',\n",
       "       'n_followers_source', 'n_followers_sink', 'n_followees_source',\n",
       "       'n_followees_sink', 'inter_followers', 'inter_followees', 'adar_index',\n",
       "       'follows_back', 'same_comp', 'shortest_path',\n",
       "       'prefential_for_followees', 'page_rank_s', 'page_rank_d', 'katz_s',\n",
       "       'katz_d'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_train.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>sink</th>\n",
       "      <th>edge_indecator</th>\n",
       "      <th>jaccard_followers</th>\n",
       "      <th>jaccard_for_followees</th>\n",
       "      <th>cosine_followers</th>\n",
       "      <th>cosine_followees</th>\n",
       "      <th>n_followers_source</th>\n",
       "      <th>n_followers_sink</th>\n",
       "      <th>n_followees_source</th>\n",
       "      <th>...</th>\n",
       "      <th>inter_followees</th>\n",
       "      <th>adar_index</th>\n",
       "      <th>follows_back</th>\n",
       "      <th>same_comp</th>\n",
       "      <th>shortest_path</th>\n",
       "      <th>prefential_for_followees</th>\n",
       "      <th>page_rank_s</th>\n",
       "      <th>page_rank_d</th>\n",
       "      <th>katz_s</th>\n",
       "      <th>katz_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401907</td>\n",
       "      <td>3562999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>94</td>\n",
       "      <td>1141</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104316</td>\n",
       "      <td>307250</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018692</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>919</td>\n",
       "      <td>1108</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>46.718745</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.020410</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.020410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3189257</td>\n",
       "      <td>4519427</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>401</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1130724</td>\n",
       "      <td>889255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.898633</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1535773</td>\n",
       "      <td>696414</td>\n",
       "      <td>1</td>\n",
       "      <td>0.214953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>174</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101098</th>\n",
       "      <td>1704301</td>\n",
       "      <td>1890334</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101099</th>\n",
       "      <td>2809708</td>\n",
       "      <td>1936487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101100</th>\n",
       "      <td>662696</td>\n",
       "      <td>4181269</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101101</th>\n",
       "      <td>1603868</td>\n",
       "      <td>4339146</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101102</th>\n",
       "      <td>4102091</td>\n",
       "      <td>1294842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101103 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         source     sink  edge_indecator  jaccard_followers  \\\n",
       "0       2401907  3562999               1           0.005102   \n",
       "1        104316   307250               1           0.018692   \n",
       "2       3189257  4519427               1           0.000000   \n",
       "3       1130724   889255               1           0.285714   \n",
       "4       1535773   696414               1           0.214953   \n",
       "...         ...      ...             ...                ...   \n",
       "101098  1704301  1890334               0           0.000000   \n",
       "101099  2809708  1936487               0           0.000000   \n",
       "101100   662696  4181269               0           0.142857   \n",
       "101101  1603868  4339146               0           0.000000   \n",
       "101102  4102091  1294842               0           0.000000   \n",
       "\n",
       "        jaccard_for_followees  cosine_followers  cosine_followees  \\\n",
       "0                    0.000000                 0                 0   \n",
       "1                    0.002678                 0                 0   \n",
       "2                    0.000000                 0                 0   \n",
       "3                    0.028986                 0                 0   \n",
       "4                    0.000000                 0                 0   \n",
       "...                       ...               ...               ...   \n",
       "101098               0.000000                 0                 0   \n",
       "101099               0.000000                 0                 0   \n",
       "101100               0.000000                 0                 0   \n",
       "101101               0.000000                 0                 0   \n",
       "101102               0.000000                 0                 0   \n",
       "\n",
       "        n_followers_source  n_followers_sink  n_followees_source  ...  \\\n",
       "0                      103                94                1141  ...   \n",
       "1                      171               919                1108  ...   \n",
       "2                       44                 3                 401  ...   \n",
       "3                        8                19                   5  ...   \n",
       "4                       86               174                 135  ...   \n",
       "...                    ...               ...                 ...  ...   \n",
       "101098                  84                 1                 192  ...   \n",
       "101099                  28                 4                 172  ...   \n",
       "101100                   6                 2                  72  ...   \n",
       "101101                   7                 2                  41  ...   \n",
       "101102                   4                 1                  24  ...   \n",
       "\n",
       "        inter_followees  adar_index  follows_back  same_comp  shortest_path  \\\n",
       "0                     0    0.000000             0          1              2   \n",
       "1                    98   46.718745             1          1              2   \n",
       "2                     0    0.000000             0          1              3   \n",
       "3                     2    1.898633             1          1              2   \n",
       "4                     0    0.000000             0          1              2   \n",
       "...                 ...         ...           ...        ...            ...   \n",
       "101098                0    0.000000             0          1              4   \n",
       "101099                0    0.000000             0          1              3   \n",
       "101100                0    0.000000             0          1              2   \n",
       "101101                0    0.000000             0          1              3   \n",
       "101102                0    0.000000             0          1              4   \n",
       "\n",
       "        prefential_for_followees  page_rank_s  page_rank_d    katz_s    katz_d  \n",
       "0                              2     0.000765     0.000114  0.000765  0.000114  \n",
       "1                              2     0.000746     0.020410  0.000746  0.020410  \n",
       "2                              3     0.000343     0.000114  0.000343  0.000114  \n",
       "3                              2     0.000117     0.000152  0.000117  0.000152  \n",
       "4                              2     0.000191     0.000114  0.000191  0.000114  \n",
       "...                          ...          ...          ...       ...       ...  \n",
       "101098                         4     0.000224     0.000114  0.000224  0.000114  \n",
       "101099                         3     0.000212     0.000114  0.000212  0.000114  \n",
       "101100                         2     0.000155     0.000114  0.000155  0.000114  \n",
       "101101                         3     0.000138     0.000114  0.000138  0.000114  \n",
       "101102                         4     0.000128     0.000114  0.000128  0.000114  \n",
       "\n",
       "[101103 rows x 22 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target data for training data\n",
    "y_train = df_final_train.edge_indecator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Feature Selection using Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha using built-in LassoCV: 5.807202\n",
      "Best score using built-in LassoCV: 0.078706\n"
     ]
    }
   ],
   "source": [
    "reg = LassoCV()\n",
    "reg.fit(df_final_train, y_train)\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %reg.score(df_final_train,y_train))\n",
    "coef = pd.Series(reg.coef_, index = df_final_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso picked 5 variables and eliminated the other 13 variables\n"
     ]
    }
   ],
   "source": [
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feature importance using Lasso Model')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp_coef = coef.sort_values()\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #drop unwanted columns\n",
    "# df_final_train.drop(['source', 'sink','edge_indecator','cosine_followers','cosine_followees','inter_followers','inter_followees',],axis=1,inplace=True)\n",
    "# df_final_test.drop(['source', 'sink','cosine_followers','cosine_followees','inter_followers','inter_followees'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>sink</th>\n",
       "      <th>jaccard_followers</th>\n",
       "      <th>jaccard_for_followees</th>\n",
       "      <th>cosine_followers</th>\n",
       "      <th>cosine_followees</th>\n",
       "      <th>n_followers_source</th>\n",
       "      <th>n_followers_sink</th>\n",
       "      <th>n_followees_source</th>\n",
       "      <th>n_followees_sink</th>\n",
       "      <th>...</th>\n",
       "      <th>inter_followees</th>\n",
       "      <th>adar_index</th>\n",
       "      <th>follows_back</th>\n",
       "      <th>same_comp</th>\n",
       "      <th>shortest_path</th>\n",
       "      <th>prefential_for_followees</th>\n",
       "      <th>page_rank_s</th>\n",
       "      <th>page_rank_d</th>\n",
       "      <th>katz_s</th>\n",
       "      <th>katz_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3563811</td>\n",
       "      <td>3600160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2052043</td>\n",
       "      <td>1401960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4517994</td>\n",
       "      <td>1690636</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>17</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1660006</td>\n",
       "      <td>4349447</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>581111</td>\n",
       "      <td>1882617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1461386</td>\n",
       "      <td>2341683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>4057755</td>\n",
       "      <td>1871227</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>41</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>4242514</td>\n",
       "      <td>1413468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>555531</td>\n",
       "      <td>1290080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1707829</td>\n",
       "      <td>2373045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       source     sink  jaccard_followers  jaccard_for_followees  \\\n",
       "0     3563811  3600160           0.000000                    0.0   \n",
       "1     2052043  1401960           0.000000                    0.0   \n",
       "2     4517994  1690636           0.021053                    0.0   \n",
       "3     1660006  4349447           0.030303                    0.0   \n",
       "4      581111  1882617           0.000000                    0.0   \n",
       "...       ...      ...                ...                    ...   \n",
       "1995  1461386  2341683           0.000000                    0.0   \n",
       "1996  4057755  1871227           0.010753                    0.0   \n",
       "1997  4242514  1413468           0.000000                    0.0   \n",
       "1998   555531  1290080           0.000000                    0.0   \n",
       "1999  1707829  2373045           0.000000                    0.0   \n",
       "\n",
       "      cosine_followers  cosine_followees  n_followers_source  \\\n",
       "0                    0                 0                   3   \n",
       "1                    0                 0                  13   \n",
       "2                    0                 0                  80   \n",
       "3                    0                 0                  32   \n",
       "4                    0                 0                   5   \n",
       "...                ...               ...                 ...   \n",
       "1995                 0                 0                  16   \n",
       "1996                 0                 0                  53   \n",
       "1997                 0                 0                   6   \n",
       "1998                 0                 0                   7   \n",
       "1999                 0                 0                  10   \n",
       "\n",
       "      n_followers_sink  n_followees_source  n_followees_sink  ...  \\\n",
       "0                   29                  21                 0  ...   \n",
       "1                    9                  71                 0  ...   \n",
       "2                   17                 205                 0  ...   \n",
       "3                   36                 506                 0  ...   \n",
       "4                   46                  18                 0  ...   \n",
       "...                ...                 ...               ...  ...   \n",
       "1995                 2                  53                 0  ...   \n",
       "1996                41                  95                 0  ...   \n",
       "1997                 2                  26                 0  ...   \n",
       "1998                 3                  56                 0  ...   \n",
       "1999                 2                 244                 0  ...   \n",
       "\n",
       "      inter_followees  adar_index  follows_back  same_comp  shortest_path  \\\n",
       "0                   0         0.0             0          1              4   \n",
       "1                   0         0.0             0          1              3   \n",
       "2                   0         0.0             0          1              2   \n",
       "3                   0         0.0             0          1              2   \n",
       "4                   0         0.0             0          1              3   \n",
       "...               ...         ...           ...        ...            ...   \n",
       "1995                0         0.0             0          1              3   \n",
       "1996                0         0.0             0          1              3   \n",
       "1997                0         0.0             0          1              3   \n",
       "1998                0         0.0             0          1              3   \n",
       "1999                0         0.0             0          1              3   \n",
       "\n",
       "      prefential_for_followees  page_rank_s  page_rank_d    katz_s    katz_d  \n",
       "0                            4     0.000126     0.000114  0.000126  0.000114  \n",
       "1                            3     0.000155     0.000114  0.000155  0.000114  \n",
       "2                            2     0.000231     0.000114  0.000231  0.000114  \n",
       "3                            2     0.000403     0.000114  0.000403  0.000114  \n",
       "4                            3     0.000124     0.000114  0.000124  0.000114  \n",
       "...                        ...          ...          ...       ...       ...  \n",
       "1995                         3     0.000144     0.000114  0.000144  0.000114  \n",
       "1996                         3     0.000168     0.000114  0.000168  0.000114  \n",
       "1997                         3     0.000129     0.000114  0.000129  0.000114  \n",
       "1998                         3     0.000146     0.000114  0.000146  0.000114  \n",
       "1999                         3     0.000253     0.000114  0.000253  0.000114  \n",
       "\n",
       "[2000 rows x 21 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final_train[['prefential_for_followees','jaccard_followers','inter_followers','n_followees_source','katz_s','katz_d','page_rank_s','adar_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prefential_for_followees', 'jaccard_followers', 'inter_followers',\n",
       "       'n_followees_source', 'katz_s', 'katz_d', 'page_rank_s', 'adar_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_final_test[['prefential_for_followees','jaccard_followers','inter_followers','n_followees_source','katz_s','katz_d','page_rank_s','adar_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 8)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101103, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefential_for_followees</th>\n",
       "      <th>jaccard_followers</th>\n",
       "      <th>inter_followers</th>\n",
       "      <th>n_followees_source</th>\n",
       "      <th>katz_s</th>\n",
       "      <th>katz_d</th>\n",
       "      <th>page_rank_s</th>\n",
       "      <th>adar_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>2</td>\n",
       "      <td>205</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>2</td>\n",
       "      <td>506</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>3</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prefential_for_followees  jaccard_followers  inter_followers  \\\n",
       "0                            4           0.000000                0   \n",
       "1                            3           0.000000                0   \n",
       "2                            2           0.021053                2   \n",
       "3                            2           0.030303                2   \n",
       "4                            3           0.000000                0   \n",
       "...                        ...                ...              ...   \n",
       "1995                         3           0.000000                0   \n",
       "1996                         3           0.010753                1   \n",
       "1997                         3           0.000000                0   \n",
       "1998                         3           0.000000                0   \n",
       "1999                         3           0.000000                0   \n",
       "\n",
       "      n_followees_source    katz_s    katz_d  page_rank_s  adar_index  \n",
       "0                     21  0.000126  0.000114     0.000126         0.0  \n",
       "1                     71  0.000155  0.000114     0.000155         0.0  \n",
       "2                    205  0.000231  0.000114     0.000231         0.0  \n",
       "3                    506  0.000403  0.000114     0.000403         0.0  \n",
       "4                     18  0.000124  0.000114     0.000124         0.0  \n",
       "...                  ...       ...       ...          ...         ...  \n",
       "1995                  53  0.000144  0.000114     0.000144         0.0  \n",
       "1996                  95  0.000168  0.000114     0.000168         0.0  \n",
       "1997                  26  0.000129  0.000114     0.000129         0.0  \n",
       "1998                  56  0.000146  0.000114     0.000146         0.0  \n",
       "1999                 244  0.000253  0.000114     0.000253         0.0  \n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define R-Sqaured\n",
    "def xgb_r2(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'r2', r2_score(preds, labels)\n",
    "  \n",
    "dtrain = xgb.DMatrix(df_final_train, y_train, feature_names=df_final_train.columns.values)\n",
    "\n",
    "# Define Objective Function\n",
    "def hyp_xgb(max_depth, subsample, colsample_bytree,min_child_weight, gamma ):\n",
    "    params = {\n",
    "    'n_estimators': 300,\n",
    "    'eta': 0.05,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric':'mae', # Optional --> Use eval_metric if you want to stop evaluation based on eval_metric \n",
    "    'silent': 1\n",
    "     }\n",
    "    params['max_depth'] = int(round(max_depth))\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    scores = xgb.cv(params, dtrain, num_boost_round=1000,verbose_eval=False, early_stopping_rounds=10, feval=xgb_r2, maximize=True, nfold=5)\n",
    "    return  scores['test-r2-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds ={\n",
    "  'min_child_weight':(14, 20),\n",
    "  'gamma':(0, 5),\n",
    "  'subsample':(0.5, 1),\n",
    "  'colsample_bytree':(0.1, 1),\n",
    "  'max_depth': (5, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | max_depth | min_ch... | subsample |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9996  \u001b[0m | \u001b[0m 0.7942  \u001b[0m | \u001b[0m 0.1038  \u001b[0m | \u001b[0m 8.168   \u001b[0m | \u001b[0m 18.49   \u001b[0m | \u001b[0m 0.7493  \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0.30231698097776294, 0.9903143237981199, 8.802653560994793, 15.014665019375213, 0.5441699070870052)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-97e15202d487>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_END\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-3a6eec09b678>\u001b[0m in \u001b[0;36mhyp_xgb\u001b[0;34m(max_depth, subsample, colsample_bytree, min_child_weight, gamma)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min_child_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_child_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gamma'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_r2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m  \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test-r2-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[1;32m    443\u001b[0m                            evaluation_result_list=None))\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Surrogate model\n",
    "\n",
    "optimizer = BayesianOptimization(hyp_xgb, pds, random_state=10)\n",
    "                                  \n",
    "# Optimize\n",
    "\n",
    "optimizer.maximize(init_points=5, n_iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [101103, 67739]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-b95ab680d496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# split data into train and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# fit model no training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2116\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2118\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \"\"\"\n\u001b[1;32m    247\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [101103, 67739]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# monitor training performance\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_train, test_size=0.33, random_state=7)\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "eval_set = [(X_test, y_test)]\n",
    "model.fit(X_train, y_train, eval_metric=\"error\", eval_set=eval_set, verbose=True)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "tuned_params = {'max_depth': [1, 2, 3, 4, 5], 'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [100, 200, 300, 400, 500], 'reg_lambda': [0.001, 0.1, 1.0, 10.0, 100.0]}\n",
    "model = RandomizedSearchCV(XGBClassifier(), tuned_params, n_iter=15, scoring = 'roc_auc', n_jobs=-1)\n",
    "model.fit(X,y_train) # actual data and actual prediction\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.00010991096496582031 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "# tuned_params = {'max_depth': [4], 'learning_rate': [0.05], 'n_estimators': [500], 'reg_lambda': [1.0]}\n",
    "\n",
    "clf = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.7, gamma=20,\n",
    "              learning_rate=0.05, max_delta_step=0, max_depth=6,\n",
    "              min_child_weight=18, missing=None, n_estimators=700, n_jobs=1,\n",
    "              nthread=None, objective='binary:logistic', random_state=42,\n",
    "              reg_alpha=25 ,reg_lambda=0, scale_pos_weight=1, seed=None,\n",
    "              silent=None, subsample=0.7, verbosity=1)\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, y_train, test_size=0.30, random_state=42)\n",
    "modelheld = clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.68%\n"
     ]
    }
   ],
   "source": [
    "result = modelheld.score(X_train,Y_train)\n",
    "print(\"Accuracy: %.2f%%\" % (result*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.80%\n"
     ]
    }
   ],
   "source": [
    "result = modelheld.score(X_test, Y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (result*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867989845372721\n",
      "0.9224829612617963\n"
     ]
    }
   ],
   "source": [
    "pre=modelheld.predict_proba(X_test)\n",
    "# print(pre)\n",
    "y_pre=[p[1] for p in pre]\n",
    "acc=modelheld.score(X_test,Y_test)\n",
    "print(acc)\n",
    "auc=roc_auc_score(Y_test,y_pre)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Skill: ROC AUC=0.500\n",
      "MLP: ROC AUC=0.923\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(Y_test))]\n",
    "# predict probabilities\n",
    "mlp_probs = model_kfold.predict_proba(X_test)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "mlp_probs = mlp_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(Y_test, ns_probs)\n",
    "\n",
    "mlp_auc=roc_auc_score(Y_test,mlp_probs)\n",
    "\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('MLP: ROC AUC=%.3f' % (mlp_auc))\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(Y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(Y_test,mlp_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='XGboost')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.39%\n"
     ]
    }
   ],
   "source": [
    "# this validation startegy improves the performance of the model and could be a better model validation strategy\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=None)\n",
    "model_kfold = clf.fit(X,y_train) # fit XGboost model\n",
    "results_kfold = model_selection.cross_val_score(model_kfold, X, y_train, cv=kfold)\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_testing = test.iloc[:,0:6].values\n",
    "predictions=model_kfold.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.72%\n"
     ]
    }
   ],
   "source": [
    "result = model_kfold.score(X, y_train)\n",
    "print(\"Accuracy: %.2f%%\" % (result*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the prediction to the csv file\n",
    "with open(\"preXG-10.csv\",\"w\",newline=\"\") as csvfile:\n",
    "    writer=csv.writer(csvfile)\n",
    "    writer.writerow([\"Id\",\"Predicted\"])\n",
    "    test_id=1\n",
    "    for prediction in predictions:\n",
    "        writer.writerow([test_id,prediction[1]])\n",
    "        test_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
